{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用5折交叉验证,增加scale_pos_weight参数\n",
    "#Score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib # 注意这个也要import一次\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, mean_squared_error, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import lightgbm as lgb\n",
    "import toad\n",
    "from toad.plot import bin_plot, badrate_plot, proportion_plot\n",
    "import pandas_profiling as pp\n",
    "from bayes_opt import BayesianOptimization\n",
    "# from skopt.space import Real, Categorical, Integer\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据加载\n",
    "train_data = pd.read_csv('./data/data128855/train.csv')\n",
    "test_data = pd.read_csv('./data/data128855/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.head(10).T\n",
    "# train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pd.concat((train_data, test_data))\n",
    "datas.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas.tail(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas.drop(columns=['_c39'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in datas.columns:\n",
    "    print(col, datas[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = datas.select_dtypes(include='O').columns\n",
    "numerical_columns = datas.select_dtypes(exclude='O').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns, numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "unique_value = []\n",
    "for col in cat_columns:\n",
    "    # print(col, datas[col].nunique())\n",
    "    col_name.append(col)\n",
    "    unique_value.append(datas[col].nunique())\n",
    "\n",
    "df_cat_col_unique = pd.DataFrame()\n",
    "df_cat_col_unique['col_name'] = col_name\n",
    "df_cat_col_unique['unique_value'] = unique_value\n",
    "df_cat_col_unique = df_cat_col_unique.sort_values('unique_value', ascending= False)\n",
    "# df_cat_col_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "unique_value = []\n",
    "for col in numerical_columns:\n",
    "    # print(col, datas[col].nunique())\n",
    "    col_name.append(col)\n",
    "    unique_value.append(datas[col].nunique())\n",
    "\n",
    "df_numerical_col_unique = pd.DataFrame()\n",
    "df_numerical_col_unique['col_name'] = col_name\n",
    "df_numerical_col_unique['unique_value'] = unique_value\n",
    "df_numerical_col_unique = df_numerical_col_unique.sort_values('unique_value', ascending= False)\n",
    "# df_numerical_col_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cat_col_unique\n",
    "df_numerical_col_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 标签编码 policy_bind_date、incident_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['policy_bind_date'] = pd.to_datetime(datas['policy_bind_date'])\n",
    "datas['incident_date'] = pd.to_datetime(datas['incident_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['policy_bind_date_year'] = datas['policy_bind_date'].dt.year\n",
    "datas['policy_bind_date_month'] = datas['policy_bind_date'].dt.month\n",
    "datas['policy_bind_date_day'] = datas['policy_bind_date'].dt.day\n",
    "datas['policy_bind_date_weekday'] = datas['policy_bind_date'].dt.weekday\n",
    "\n",
    "datas['incident_date_year'] = datas['incident_date'].dt.year\n",
    "datas['incident_date_month'] = datas['incident_date'].dt.month\n",
    "datas['incident_date_day'] = datas['incident_date'].dt.day\n",
    "datas['incident_date_weekday'] = datas['incident_date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看最小、最大日期\n",
    "# datas.policy_bind_date.min() #1990-01-08\n",
    "# datas.policy_bind_date.max() #2015-02-22\n",
    "\n",
    "# datas.incident_date.min() #2015-01-01\n",
    "# datas.incident_date.max() #2015-03-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_date = datas.policy_bind_date.min()\n",
    "#转换为diff\n",
    "datas['policy_bind_date_diff'] = (datas['policy_bind_date'] - base_date).dt.days\n",
    "datas['incident_date_diff'] = (datas['incident_date'] - base_date).dt.days\n",
    "datas['incident_date&policy_bind_date_diff'] = datas['incident_date_diff'] - datas['policy_bind_date_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造交叉业务特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['injury_claim_pct'] = datas['injury_claim']/datas['total_claim_amount']\n",
    "datas['property_claim_pct'] = datas['property_claim']/datas['total_claim_amount']\n",
    "datas['vehicle_claim_pct'] = datas['vehicle_claim']/datas['total_claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['is_injury_claim'] = datas['injury_claim'].apply(lambda x: '1' if x >0 else '0')\n",
    "datas['is_property_claim'] = datas['property_claim'].apply(lambda x: '1' if x >0 else '0')\n",
    "datas['is_vehicle_claim'] = datas['vehicle_claim'].apply(lambda x: '1' if x >0 else '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['incident_type_&_is_injury_claim'] = datas['incident_type'] + '_' + datas['is_injury_claim']\n",
    "datas['incident_type_&_is_property_claim'] = datas['incident_type'] + '_' + datas['is_property_claim']\n",
    "datas['incident_type_&_is_vehicle_claim'] = datas['incident_type'] + '_' + datas['is_vehicle_claim']\n",
    "\n",
    "datas['collision_type_&_is_injury_claim'] = datas['collision_type'] + '_' + datas['is_injury_claim']\n",
    "datas['collision_type_&_is_property_claim'] = datas['collision_type'] + '_' + datas['is_property_claim']\n",
    "datas['collision_type_&_is_vehicle_claim'] = datas['collision_type'] + '_' + datas['is_vehicle_claim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['umbrella_limit_2_total_claim_amount'] = datas['umbrella_limit']/datas['total_claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['G/L'] = datas['capital-gains'] + datas['capital-loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#检查单个特征\n",
    "# datas.bodily_injuries.nunique()\n",
    "# datas.bodily_injuries.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas.drop(['policy_bind_date', 'incident_date', '_c39', 'incident_location', 'policy_number', 'insured_zip'], axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = datas.select_dtypes(include= 'O').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in cat_columns:\n",
    "#     le = LabelEncoder()\n",
    "#     datas[col] = le.fit_transform(datas[col])\n",
    "\n",
    "# datas[cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集切分\n",
    "train = datas[datas['fraud_reported'].notnull()]\n",
    "test = datas[datas['fraud_reported'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop(columns=['fraud_reported'])\n",
    "train_y = train['fraud_reported']\n",
    "test_X = test.drop(columns=['fraud_reported'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用catboost 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier, cv, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 标记分类变量\n",
    "# categorical_fea = ['initialListStatus', 'employmentTitle', 'applicationType', \n",
    "#                    'title', 'policyCode', 'purpose', 'regionCode', 'postCode',\n",
    "#                    'verificationStatus', 'homeOwnership']\n",
    "categorical_fea = list(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in data_X.columns:\n",
    "#     if i in categorical_fea:\n",
    "#         data_X[i] = data_X[i].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in data_X_testA.columns:\n",
    "#     if i in categorical_fea:\n",
    "#         data_X_testA[i] = data_X_testA[i].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "answers = []\n",
    "mean_score = 0\n",
    "cv_scores = []\n",
    "NFOLD = 5\n",
    "seed = 2022\n",
    "CB_INFO_PATH = '/home/aistudio/catboost_info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=NFOLD, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.utils import get_gpu_device_count\n",
    "print('I see %i GPU devices' % get_gpu_device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cat_model = cb.CatBoostClassifier(loss_function='Logloss', eval_metric='AUC', \n",
    "                                     iterations=20000, #max_leaves=2**6-1, \n",
    "                                     depth=6, learning_rate=0.005,\n",
    "                                     random_state=2022, od_type=\"Iter\",\n",
    "                                     subsample=0.8, colsample_bylevel=0.8, min_data_in_leaf=3, l2_leaf_reg=0.5,\n",
    "                                    #  scale_pos_weight = 4,\n",
    "                                     use_best_model=True, metric_period=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_index, val_index) in enumerate(kf.split(train_X, train_y)):\n",
    "    X_train_fold, X_val_fold = train_X.iloc[train_index], train_X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = train_y.iloc[train_index], train_y.iloc[val_index]\n",
    "    \n",
    "    print(\"fold:\", fold)\n",
    "    clf = cv_cat_model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold),\n",
    "                           verbose=100, \n",
    "                           cat_features=categorical_fea,\n",
    "                           )\n",
    "    clfs.append(clf)\n",
    "\n",
    "    pred_val_fold = clfs[fold].predict(X_val_fold, prediction_type='Probability',\n",
    "                                       ntree_end = clfs[fold].get_best_iteration())[:,-1]\n",
    "    \n",
    "    print('cat验证的auc:{}'.format(roc_auc_score(y_val_fold, pred_val_fold)))\n",
    "    mean_score += roc_auc_score(y_val_fold, pred_val_fold) / NFOLD\n",
    "    cv_scores.append(roc_auc_score(y_val_fold, pred_val_fold))\n",
    "\n",
    "    pred = clfs[fold].predict(test_X, prediction_type='Probability',\n",
    "                              ntree_end = clfs[fold].get_best_iteration())[:,-1]\n",
    "    answers.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cat_scotrainre_list:{}\".format(cv_scores))\n",
    "print(\"cat_score_mean:{}\".format(np.mean(cv_scores)))\n",
    "print(\"cat_score_std:{}\".format(np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最终加权平均的预测结果\n",
    "cat_pre=sum(answers)/NFOLD\n",
    "cat_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./data/data128855/sampleSubmission.csv')\n",
    "submission['fraud_reported'] = cat_pre\n",
    "submission.to_csv('./work/submission/submission.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
