{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#增加交叉特征\n",
    "#Score: Score: 0.89048\n",
    "#使用5折交叉验证,增加scale_pos_weight参数\n",
    "#Score: Score: 0.89292\n",
    "#增加G/L\n",
    "#Score: 0.88696\n",
    "#交叉特征增加location_type，不使用G/L\n",
    "#Score: 0.88777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib # 注意这个也要import一次\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, mean_squared_error, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据加载\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pd.concat((train_data, test_data))\n",
    "datas.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = datas.select_dtypes(include=['O']).columns\n",
    "numerical_columns = datas.select_dtypes(exclude=['O']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "unique_value = []\n",
    "for col in cat_columns:\n",
    "    # print(col, datas[col].nunique())\n",
    "    col_name.append(col)\n",
    "    unique_value.append(datas[col].nunique())\n",
    "\n",
    "df_cat_col_unique = pd.DataFrame()\n",
    "df_cat_col_unique['col_name'] = col_name\n",
    "df_cat_col_unique['unique_value'] = unique_value\n",
    "df_cat_col_unique = df_cat_col_unique.sort_values('unique_value', ascending= False)\n",
    "# df_cat_col_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "unique_value = []\n",
    "for col in numerical_columns:\n",
    "    # print(col, datas[col].nunique())\n",
    "    col_name.append(col)\n",
    "    unique_value.append(datas[col].nunique())\n",
    "\n",
    "df_numerical_col_unique = pd.DataFrame()\n",
    "df_numerical_col_unique['col_name'] = col_name\n",
    "df_numerical_col_unique['unique_value'] = unique_value\n",
    "df_numerical_col_unique = df_numerical_col_unique.sort_values('unique_value', ascending= False)\n",
    "# df_numerical_col_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>unique_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>incident_location</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>policy_bind_date</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>incident_date</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>auto_model</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>insured_hobbies</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>insured_occupation</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>auto_make</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insured_education_level</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>incident_state</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>incident_city</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>insured_relationship</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>authorities_contacted</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>incident_type</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>incident_severity</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>collision_type</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>policy_state</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>policy_csl</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>property_damage</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>police_report_available</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insured_sex</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   col_name  unique_value\n",
       "15        incident_location          1000\n",
       "0          policy_bind_date           951\n",
       "8             incident_date            60\n",
       "19               auto_model            39\n",
       "6           insured_hobbies            20\n",
       "5        insured_occupation            14\n",
       "18                auto_make            14\n",
       "4   insured_education_level             7\n",
       "13           incident_state             7\n",
       "14            incident_city             7\n",
       "7      insured_relationship             6\n",
       "12    authorities_contacted             5\n",
       "9             incident_type             4\n",
       "11        incident_severity             4\n",
       "10           collision_type             4\n",
       "1              policy_state             3\n",
       "2                policy_csl             3\n",
       "16          property_damage             3\n",
       "17  police_report_available             3\n",
       "3               insured_sex             2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_col_unique\n",
    "# df_numerical_col_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 标签编码 policy_bind_date、incident_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['policy_bind_date'] = pd.to_datetime(datas['policy_bind_date'])\n",
    "datas['incident_date'] = pd.to_datetime(datas['incident_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['policy_bind_date_year'] = datas['policy_bind_date'].dt.year\n",
    "datas['policy_bind_date_month'] = datas['policy_bind_date'].dt.month\n",
    "datas['policy_bind_date_day'] = datas['policy_bind_date'].dt.day\n",
    "datas['policy_bind_date_weekday'] = datas['policy_bind_date'].dt.weekday\n",
    "\n",
    "datas['incident_date_year'] = datas['incident_date'].dt.year\n",
    "datas['incident_date_month'] = datas['incident_date'].dt.month\n",
    "datas['incident_date_day'] = datas['incident_date'].dt.day\n",
    "datas['incident_date_weekday'] = datas['incident_date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看最小、最大日期\n",
    "# datas.policy_bind_date.min() #1990-01-08\n",
    "# datas.policy_bind_date.max() #2015-02-22\n",
    "\n",
    "# datas.incident_date.min() #2015-01-01\n",
    "# datas.incident_date.max() #2015-03-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_date = datas.policy_bind_date.min()\n",
    "#转换为diff\n",
    "datas['policy_bind_date_diff'] = (datas['policy_bind_date'] - base_date).dt.days\n",
    "datas['incident_date_diff'] = (datas['incident_date'] - base_date).dt.days\n",
    "datas['incident_date&policy_bind_date_diff'] = datas['incident_date_diff'] - datas['policy_bind_date_diff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造交叉业务特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['injury_claim_pct'] = datas['injury_claim']/datas['total_claim_amount']\n",
    "datas['property_claim_pct'] = datas['property_claim']/datas['total_claim_amount']\n",
    "datas['vehicle_claim_pct'] = datas['vehicle_claim']/datas['total_claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['is_injury_claim'] = datas['injury_claim'].apply(lambda x: '1' if x >0 else '0')\n",
    "datas['is_property_claim'] = datas['property_claim'].apply(lambda x: '1' if x >0 else '0')\n",
    "datas['is_vehicle_claim'] = datas['vehicle_claim'].apply(lambda x: '1' if x >0 else '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['incident_type_&_is_injury_claim'] = datas['incident_type'] + '_' + datas['is_injury_claim']\n",
    "datas['incident_type_&_is_property_claim'] = datas['incident_type'] + '_' + datas['is_property_claim']\n",
    "datas['incident_type_&_is_vehicle_claim'] = datas['incident_type'] + '_' + datas['is_vehicle_claim']\n",
    "\n",
    "datas['collision_type_&_is_injury_claim'] = datas['collision_type'] + '_' + datas['is_injury_claim']\n",
    "datas['collision_type_&_is_property_claim'] = datas['collision_type'] + '_' + datas['is_property_claim']\n",
    "datas['collision_type_&_is_vehicle_claim'] = datas['collision_type'] + '_' + datas['is_vehicle_claim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['umbrella_limit_2_total_claim_amount'] = datas['umbrella_limit']/datas['total_claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas['G/L'] = datas['capital-gains'] + datas['capital-loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas['location_type'] = datas['incident_location'].apply(lambda x: x.split()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas[['incident_type', 'collision_type', 'policy_csl', 'policy_annual_premium', 'umbrella_limit', 'total_claim_amount', 'injury_claim', 'property_claim', 'vehicle_claim', 'capital-gains', 'capital-loss']][datas['fraud_reported'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#检查单个特征\n",
    "# datas.incident_city.nunique()\n",
    "# datas['incident_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas.drop(['policy_bind_date', 'incident_date', '_c39', 'incident_location', 'policy_number', 'insured_zip'], axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = datas.select_dtypes(include= ['O']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_columns:\n",
    "    le = LabelEncoder()\n",
    "    datas[col] = le.fit_transform(datas[col])\n",
    "\n",
    "datas[cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集切分\n",
    "train = datas[datas['fraud_reported'].notnull()]\n",
    "test = datas[datas['fraud_reported'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop(['fraud_reported'], axis=1)\n",
    "train_y = train['fraud_reported']\n",
    "test_X = test.drop(['fraud_reported'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用lgbm 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMClassifier(\n",
    "            num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='binary',\n",
    "            max_depth=-1, learning_rate=0.005, min_child_samples=3, random_state=2022,\n",
    "            n_estimators=2000, subsample=1, colsample_bytree=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lgb.predict_proba(test_X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,18))\n",
    "lgb.plot_importance(model_lgb, max_num_features=50, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.read_csv('./data/sampleSubmission.csv')\n",
    "# submission['fraud_reported'] = y_pred\n",
    "# submission.to_csv('./submission/submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用五折交叉验证的LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb = {\n",
    "    'num_leaves': 2**5-1, 'reg_alpha': 0.25, 'reg_lambda': 0.25, 'objective': 'binary',\n",
    "    'max_depth': -1, 'learning_rate': 0.005, 'min_child_samples': 3, 'random_state': 2022,\n",
    "    #'n_estimators': 2000, \n",
    "    'subsample': 1, 'colsample_bytree': 1, 'scale_pos_weight': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits = NFOLD, shuffle = True, random_state = 2022)\n",
    "\n",
    "y_pred = np.zeros(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_index, val_index) in enumerate(kf.split(train_X, train_y)):\n",
    "    X_fold_train, X_fold_val = train_X.iloc[train_index, :], train_X.iloc[val_index, :]\n",
    "    y_fold_train, y_fold_val = train_y[train_index], train_y[val_index]\n",
    "    train_set = lgb.Dataset(X_fold_train, y_fold_train)\n",
    "    val_set = lgb.Dataset(X_fold_val, y_fold_val, reference=train_set)\n",
    "\n",
    "    model_lgb = lgb.train(params_lgb, train_set, num_boost_round=2000, #early_stopping_rounds=50,\n",
    "                      valid_sets = val_set, verbose_eval=100)\n",
    "\n",
    "    print('kf.n_splits:', kf.n_splits)\n",
    "    y_pred += model_lgb.predict(test_X, num_iteration=model_lgb.best_iteration)/kf.n_splits\n",
    "\n",
    "# y_pred = [1 if y > 0.5 else 0 for y in y_pred]\n",
    "# rmse = metrics.accuracy_score(y_pred,y_test)\n",
    "# print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./data/sampleSubmission.csv')\n",
    "submission['fraud_reported'] = y_pred\n",
    "submission.to_csv('./submission/submission.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
